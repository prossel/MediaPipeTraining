{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bfedfe",
   "metadata": {},
   "source": [
    "# Synthetic COCO Dataset Generation\n",
    "\n",
    "This notebook generates synthetic images with object annotations in COCO format for training an object detection model. The objects are white shapes (baton, clubs, coin, diamond, heart) that will be detected by a webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa4157",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97f27b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Classes\n",
    "    'classes': {\n",
    "        0: 'background',\n",
    "        1: 'baton',\n",
    "        2: 'clubs',\n",
    "        3: 'coin',\n",
    "        4: 'diamond',\n",
    "        5: 'heart'\n",
    "    },\n",
    "    \n",
    "    # Paths to shape templates\n",
    "    'shape_paths': {\n",
    "        'baton': 'assets/shapes/baton.png',\n",
    "        'clubs': 'assets/shapes/clubs.png',\n",
    "        'coin': 'assets/shapes/coin.png',\n",
    "        'diamond': 'assets/shapes/diamond.png',\n",
    "        'heart': 'assets/shapes/heart.png'\n",
    "    },\n",
    "    \n",
    "    # Output settings\n",
    "    'output_dir': 'output',\n",
    "    'train_dir': 'train',\n",
    "    'val_dir': 'val',\n",
    "    'train_ratio': 0.8,  # 80% train, 20% validation\n",
    "    \n",
    "    # Image generation settings\n",
    "    'num_images': 100,  # Total number of images to generate\n",
    "    'image_width': 640,\n",
    "    'image_height': 480,\n",
    "    'min_objects': 1,\n",
    "    'max_objects': 3,\n",
    "    \n",
    "    # Object transformation settings\n",
    "    'min_scale': 0.3,\n",
    "    'max_scale': 0.8,\n",
    "    'min_rotation': 0,\n",
    "    'max_rotation': 360,\n",
    "    \n",
    "    # Background settings\n",
    "    'background_complexity': 'high',  # low, medium, high\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5a9b1",
   "metadata": {},
   "source": [
    "## Helper Functions for Background Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_procedural_background(width, height, complexity='medium'):\n",
    "    \"\"\"\n",
    "    Generate a procedural background with varying complexity.\n",
    "    \n",
    "    Args:\n",
    "        width: Image width\n",
    "        height: Image height\n",
    "        complexity: 'low', 'medium', or 'high'\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image\n",
    "    \"\"\"\n",
    "    # Create base with random color\n",
    "    base_color = tuple(random.randint(100, 255) for _ in range(3))\n",
    "    img = Image.new('RGB', (width, height), base_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if complexity in ['medium', 'high']:\n",
    "        # Add gradient\n",
    "        for y in range(height):\n",
    "            gradient_factor = y / height\n",
    "            color = tuple(int(c * (1 - gradient_factor * 0.3)) for c in base_color)\n",
    "            draw.line([(0, y), (width, y)], fill=color)\n",
    "    \n",
    "    if complexity == 'high':\n",
    "        # Add random shapes for texture\n",
    "        num_shapes = random.randint(5, 15)\n",
    "        for _ in range(num_shapes):\n",
    "            shape_type = random.choice(['rectangle', 'ellipse', 'polygon'])\n",
    "            x1, y1 = random.randint(0, width), random.randint(0, height)\n",
    "            x2, y2 = x1 + random.randint(50, 200), y1 + random.randint(50, 200)\n",
    "            \n",
    "            color = tuple(random.randint(max(0, base_color[i] - 50), \n",
    "                                       min(255, base_color[i] + 50)) for i in range(3))\n",
    "            \n",
    "            if shape_type == 'rectangle':\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=color, outline=None)\n",
    "            elif shape_type == 'ellipse':\n",
    "                draw.ellipse([x1, y1, x2, y2], fill=color, outline=None)\n",
    "    \n",
    "    # Add noise\n",
    "    noise_level = {'low': 10, 'medium': 20, 'high': 30}[complexity]\n",
    "    np_img = np.array(img)\n",
    "    noise = np.random.randint(-noise_level, noise_level, np_img.shape, dtype=np.int16)\n",
    "    np_img = np.clip(np_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    img = Image.fromarray(np_img)\n",
    "    \n",
    "    # Apply slight blur for realism\n",
    "    img = img.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Test background generation\n",
    "test_bg = generate_procedural_background(640, 480, 'medium')\n",
    "print(\"Background generation function created successfully!\")\n",
    "test_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32ea52",
   "metadata": {},
   "source": [
    "## Load Shape Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f37b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape_templates(shape_paths):\n",
    "    \"\"\"\n",
    "    Load all shape templates from disk.\n",
    "    \n",
    "    Args:\n",
    "        shape_paths: Dictionary mapping shape names to file paths\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of shape name to PIL Image\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    for shape_name, path in shape_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            img = Image.open(path).convert('RGBA')\n",
    "            templates[shape_name] = img\n",
    "            print(f\"Loaded {shape_name}: {img.size}\")\n",
    "        else:\n",
    "            print(f\"Warning: {path} not found!\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "# Load templates\n",
    "shape_templates = load_shape_templates(CONFIG['shape_paths'])\n",
    "print(f\"\\nLoaded {len(shape_templates)} shape templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066b77e",
   "metadata": {},
   "source": [
    "## Object Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_object(img, scale, rotation):\n",
    "    \"\"\"\n",
    "    Apply scale and rotation transformations to an object.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image (RGBA)\n",
    "        scale: Scale factor\n",
    "        rotation: Rotation angle in degrees\n",
    "    \n",
    "    Returns:\n",
    "        Transformed PIL Image (RGBA)\n",
    "    \"\"\"\n",
    "    # Scale\n",
    "    new_width = int(img.width * scale)\n",
    "    new_height = int(img.height * scale)\n",
    "    img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    # Rotate\n",
    "    img = img.rotate(rotation, expand=True, resample=Image.BICUBIC)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def get_bounding_box(img):\n",
    "    \"\"\"\n",
    "    Get the bounding box of non-transparent pixels in an RGBA image.\n",
    "    \n",
    "    Args:\n",
    "        img: PIL Image (RGBA)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple (x_min, y_min, width, height)\n",
    "    \"\"\"\n",
    "    # Get alpha channel\n",
    "    alpha = np.array(img.split()[-1])\n",
    "    \n",
    "    # Find non-transparent pixels\n",
    "    rows = np.any(alpha > 0, axis=1)\n",
    "    cols = np.any(alpha > 0, axis=0)\n",
    "    \n",
    "    if not rows.any() or not cols.any():\n",
    "        return None\n",
    "    \n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    \n",
    "    return (int(x_min), int(y_min), int(width), int(height))\n",
    "\n",
    "\n",
    "def place_object_on_background(background, obj_img, position):\n",
    "    \"\"\"\n",
    "    Place an object on a background at a given position.\n",
    "    \n",
    "    Args:\n",
    "        background: PIL Image (RGB)\n",
    "        obj_img: PIL Image (RGBA)\n",
    "        position: Tuple (x, y) for top-left corner\n",
    "    \n",
    "    Returns:\n",
    "        Modified background image and bounding box relative to background\n",
    "    \"\"\"\n",
    "    # Get object bounding box\n",
    "    obj_bbox = get_bounding_box(obj_img)\n",
    "    if obj_bbox is None:\n",
    "        return background, None\n",
    "    \n",
    "    # Paste object on background\n",
    "    background.paste(obj_img, position, obj_img)\n",
    "    \n",
    "    # Calculate bounding box relative to background\n",
    "    x, y = position\n",
    "    obj_x, obj_y, obj_w, obj_h = obj_bbox\n",
    "    \n",
    "    bbox = (x + obj_x, y + obj_y, obj_w, obj_h)\n",
    "    \n",
    "    return background, bbox\n",
    "\n",
    "print(\"Transformation functions created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673a9c2",
   "metadata": {},
   "source": [
    "## COCO Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coco_structure():\n",
    "    \"\"\"\n",
    "    Create the initial COCO dataset structure.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with COCO format structure\n",
    "    \"\"\"\n",
    "    # Get category information from CONFIG\n",
    "    categories = []\n",
    "    for cat_id, cat_name in CONFIG['classes'].items():\n",
    "        # Include all categories, including background (category 0)\n",
    "        categories.append({\n",
    "            'id': cat_id,\n",
    "            'name': cat_name,\n",
    "            'supercategory': 'shape'\n",
    "        })\n",
    "    \n",
    "    coco_structure = {\n",
    "        'info': {\n",
    "            'description': 'Synthetic Object Detection Dataset',\n",
    "            'version': '1.0',\n",
    "            'year': 2025,\n",
    "            'date_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        },\n",
    "        'licenses': [],\n",
    "        'categories': categories,\n",
    "        'images': [],\n",
    "        'annotations': []\n",
    "    }\n",
    "    \n",
    "    return coco_structure\n",
    "\n",
    "\n",
    "def add_image_to_coco(coco_dict, image_id, file_name, width, height):\n",
    "    \"\"\"\n",
    "    Add an image entry to COCO structure.\n",
    "    \"\"\"\n",
    "    image_entry = {\n",
    "        'id': image_id,\n",
    "        'file_name': file_name,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'date_captured': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    coco_dict['images'].append(image_entry)\n",
    "\n",
    "\n",
    "def add_annotation_to_coco(coco_dict, annotation_id, image_id, category_id, bbox):\n",
    "    \"\"\"\n",
    "    Add an annotation entry to COCO structure.\n",
    "    \n",
    "    Args:\n",
    "        coco_dict: COCO structure dictionary\n",
    "        annotation_id: Unique annotation ID\n",
    "        image_id: ID of the image this annotation belongs to\n",
    "        category_id: Category ID (class)\n",
    "        bbox: Tuple (x, y, width, height) in pixels\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    area = w * h\n",
    "    \n",
    "    annotation = {\n",
    "        'id': annotation_id,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'bbox': [float(x), float(y), float(w), float(h)],\n",
    "        'area': float(area),\n",
    "        'iscrowd': 0\n",
    "    }\n",
    "    coco_dict['annotations'].append(annotation)\n",
    "\n",
    "print(\"COCO structure functions created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1270ed",
   "metadata": {},
   "source": [
    "## Image Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51696196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_image(templates, config):\n",
    "    \"\"\"\n",
    "    Generate a single synthetic image with random objects.\n",
    "    \n",
    "    Args:\n",
    "        templates: Dictionary of shape templates\n",
    "        config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Tuple (PIL Image, list of annotations)\n",
    "        Annotations: list of dicts with 'category_id' and 'bbox'\n",
    "    \"\"\"\n",
    "    # Create background\n",
    "    background = generate_procedural_background(\n",
    "        config['image_width'],\n",
    "        config['image_height'],\n",
    "        config['background_complexity']\n",
    "    )\n",
    "    \n",
    "    # Determine number of objects\n",
    "    num_objects = random.randint(config['min_objects'], config['max_objects'])\n",
    "    \n",
    "    # List to store annotations\n",
    "    annotations = []\n",
    "    \n",
    "    # Get list of available shape names (excluding background)\n",
    "    shape_names = [name for name in templates.keys()]\n",
    "    \n",
    "    for _ in range(num_objects):\n",
    "        # Select random shape\n",
    "        shape_name = random.choice(shape_names)\n",
    "        shape_img = templates[shape_name].copy()\n",
    "        \n",
    "        # Get category_id from class name\n",
    "        category_id = None\n",
    "        for cat_id, cat_name in config['classes'].items():\n",
    "            if cat_name == shape_name:\n",
    "                category_id = cat_id\n",
    "                break\n",
    "        \n",
    "        if category_id is None:\n",
    "            continue\n",
    "        \n",
    "        # Random transformations\n",
    "        scale = random.uniform(config['min_scale'], config['max_scale'])\n",
    "        rotation = random.uniform(config['min_rotation'], config['max_rotation'])\n",
    "        \n",
    "        # Transform object\n",
    "        transformed_obj = transform_object(shape_img, scale, rotation)\n",
    "        \n",
    "        # Random position (ensure object fits in image)\n",
    "        max_x = max(0, config['image_width'] - transformed_obj.width)\n",
    "        max_y = max(0, config['image_height'] - transformed_obj.height)\n",
    "        \n",
    "        if max_x <= 0 or max_y <= 0:\n",
    "            continue\n",
    "        \n",
    "        position = (random.randint(0, max_x), random.randint(0, max_y))\n",
    "        \n",
    "        # Place object on background\n",
    "        background, bbox = place_object_on_background(background, transformed_obj, position)\n",
    "        \n",
    "        if bbox is not None:\n",
    "            # Store annotation\n",
    "            annotations.append({\n",
    "                'category_id': category_id,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "    \n",
    "    return background, annotations\n",
    "\n",
    "print(\"Image generation function created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544e9e2",
   "metadata": {},
   "source": [
    "## Test Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a test image to verify everything works\n",
    "if shape_templates:\n",
    "    test_img, test_annotations = generate_synthetic_image(shape_templates, CONFIG)\n",
    "    print(f\"Generated test image with {len(test_annotations)} objects\")\n",
    "    for ann in test_annotations:\n",
    "        cat_name = CONFIG['classes'][ann['category_id']]\n",
    "        print(f\"  - {cat_name}: bbox {ann['bbox']}\")\n",
    "    \n",
    "    # Display the test image\n",
    "    display(test_img)\n",
    "else:\n",
    "    print(\"No shape templates loaded. Please check the paths in CONFIG.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbf304",
   "metadata": {},
   "source": [
    "## Main Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76213db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(templates, config):\n",
    "    \"\"\"\n",
    "    Generate the complete synthetic dataset.\n",
    "    \n",
    "    Args:\n",
    "        templates: Dictionary of shape templates\n",
    "        config: Configuration dictionary\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    train_dir = output_dir / config['train_dir']\n",
    "    val_dir = output_dir / config['val_dir']\n",
    "    \n",
    "    train_images_dir = train_dir / 'images'\n",
    "    val_images_dir = val_dir / 'images'\n",
    "    \n",
    "    train_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    val_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"Output directories created:\")\n",
    "    print(f\"  - {train_images_dir}\")\n",
    "    print(f\"  - {val_images_dir}\")\n",
    "    \n",
    "    # Initialize COCO structures\n",
    "    train_coco = create_coco_structure()\n",
    "    val_coco = create_coco_structure()\n",
    "    \n",
    "    # Calculate split\n",
    "    num_train = int(config['num_images'] * config['train_ratio'])\n",
    "    num_val = config['num_images'] - num_train\n",
    "    \n",
    "    print(f\"\\nGenerating {config['num_images']} images:\")\n",
    "    print(f\"  - Training: {num_train}\")\n",
    "    print(f\"  - Validation: {num_val}\")\n",
    "    \n",
    "    # Counters\n",
    "    annotation_id = 1\n",
    "    \n",
    "    # Generate training images\n",
    "    print(\"\\nGenerating training images...\")\n",
    "    for i in range(num_train):\n",
    "        # Generate image\n",
    "        img, annotations = generate_synthetic_image(templates, config)\n",
    "        \n",
    "        # Save image\n",
    "        image_id = i + 1\n",
    "        file_name = f\"train_{image_id:06d}.jpg\"\n",
    "        img_path = train_images_dir / file_name\n",
    "        img.save(img_path, 'JPEG', quality=95)\n",
    "        \n",
    "        # Add to COCO structure\n",
    "        add_image_to_coco(train_coco, image_id, file_name, \n",
    "                         config['image_width'], config['image_height'])\n",
    "        \n",
    "        for ann in annotations:\n",
    "            add_annotation_to_coco(train_coco, annotation_id, image_id,\n",
    "                                  ann['category_id'], ann['bbox'])\n",
    "            annotation_id += 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Generated {i + 1}/{num_train} training images\")\n",
    "    \n",
    "    # Generate validation images\n",
    "    print(\"\\nGenerating validation images...\")\n",
    "    annotation_id = 1  # Reset for validation\n",
    "    for i in range(num_val):\n",
    "        # Generate image\n",
    "        img, annotations = generate_synthetic_image(templates, config)\n",
    "        \n",
    "        # Save image\n",
    "        image_id = i + 1\n",
    "        file_name = f\"val_{image_id:06d}.jpg\"\n",
    "        img_path = val_images_dir / file_name\n",
    "        img.save(img_path, 'JPEG', quality=95)\n",
    "        \n",
    "        # Add to COCO structure\n",
    "        add_image_to_coco(val_coco, image_id, file_name,\n",
    "                         config['image_width'], config['image_height'])\n",
    "        \n",
    "        for ann in annotations:\n",
    "            add_annotation_to_coco(val_coco, annotation_id, image_id,\n",
    "                                  ann['category_id'], ann['bbox'])\n",
    "            annotation_id += 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0 or (i + 1) == num_val:\n",
    "            print(f\"  Generated {i + 1}/{num_val} validation images\")\n",
    "    \n",
    "    # Save COCO annotations\n",
    "    train_annotations_path = train_dir / 'labels.json'\n",
    "    val_annotations_path = val_dir / 'labels.json'\n",
    "    \n",
    "    with open(train_annotations_path, 'w') as f:\n",
    "        json.dump(train_coco, f, indent=2)\n",
    "    \n",
    "    with open(val_annotations_path, 'w') as f:\n",
    "        json.dump(val_coco, f, indent=2)\n",
    "    \n",
    "    # Save configuration for reference during training/evaluation\n",
    "    config_path = output_dir / 'config.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nAnnotations saved:\")\n",
    "    print(f\"  - {train_annotations_path}\")\n",
    "    print(f\"  - {val_annotations_path}\")\n",
    "    print(f\"\\nConfiguration saved:\")\n",
    "    print(f\"  - {config_path}\")\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"  Training images: {len(train_coco['images'])}\")\n",
    "    print(f\"  Training annotations: {len(train_coco['annotations'])}\")\n",
    "    print(f\"  Validation images: {len(val_coco['images'])}\")\n",
    "    print(f\"  Validation annotations: {len(val_coco['annotations'])}\")\n",
    "    print(f\"  Classes: {len(train_coco['categories'])}\")\n",
    "    \n",
    "    return train_coco, val_coco\n",
    "\n",
    "print(\"Dataset generation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0db05b",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Helper function to load the saved configuration from a dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_config(dataset_dir):\n",
    "    \"\"\"\n",
    "    Load the configuration file from a dataset directory.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: Path to the dataset output directory\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with configuration parameters\n",
    "    \"\"\"\n",
    "    config_path = Path(dataset_dir) / 'config.json'\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    return config\n",
    "\n",
    "print(\"Configuration loader function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96359edd",
   "metadata": {},
   "source": [
    "## Generate the Dataset\n",
    "\n",
    "Run this cell to generate the complete synthetic dataset. Adjust the `num_images` in CONFIG if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "if shape_templates:\n",
    "    train_coco, val_coco = generate_dataset(shape_templates, CONFIG)\n",
    "    print(\"\\nâœ… Dataset generation complete!\")\n",
    "else:\n",
    "    print(\"âŒ Cannot generate dataset: No shape templates loaded.\")\n",
    "    print(\"Please check that the shape images exist in the assets/shapes/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1511b",
   "metadata": {},
   "source": [
    "## Visualize Sample Images\n",
    "\n",
    "Let's visualize a few generated images with their bounding boxes to verify the dataset quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0901c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_annotations(image_path, annotations, categories):\n",
    "    \"\"\"\n",
    "    Visualize an image with its bounding box annotations.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image\n",
    "        annotations: List of annotation dictionaries\n",
    "        categories: List of category dictionaries from COCO format\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image with bounding boxes drawn\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Create category lookup\n",
    "    cat_lookup = {cat['id']: cat['name'] for cat in categories}\n",
    "    \n",
    "    # Colors for different classes\n",
    "    colors = {\n",
    "        'baton': 'red',\n",
    "        'clubs': 'green',\n",
    "        'coin': 'blue',\n",
    "        'diamond': 'yellow',\n",
    "        'heart': 'magenta'\n",
    "    }\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for ann in annotations:\n",
    "        x, y, w, h = ann['bbox']\n",
    "        cat_name = cat_lookup[ann['category_id']]\n",
    "        color = colors.get(cat_name, 'white')\n",
    "        \n",
    "        # Draw rectangle\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=color, width=3)\n",
    "        \n",
    "        # Draw label\n",
    "        draw.text((x, y - 15), cat_name, fill=color)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Visualize a few training images\n",
    "if shape_templates and 'train_coco' in locals():\n",
    "    print(\"Sample Training Images with Annotations:\\n\")\n",
    "    \n",
    "    train_dir = Path(CONFIG['output_dir']) / CONFIG['train_dir']\n",
    "    \n",
    "    # Show 3 random samples\n",
    "    sample_indices = random.sample(range(len(train_coco['images'])), min(3, len(train_coco['images'])))\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        img_info = train_coco['images'][idx]\n",
    "        img_path = train_dir / 'images' / img_info['file_name']\n",
    "        \n",
    "        # Get annotations for this image\n",
    "        img_annotations = [ann for ann in train_coco['annotations'] \n",
    "                          if ann['image_id'] == img_info['id']]\n",
    "        \n",
    "        print(f\"\\n{img_info['file_name']}: {len(img_annotations)} objects\")\n",
    "        \n",
    "        # Visualize\n",
    "        vis_img = visualize_annotations(img_path, img_annotations, train_coco['categories'])\n",
    "        display(vis_img)\n",
    "else:\n",
    "    print(\"Dataset not yet generated. Run the generation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaeca4",
   "metadata": {},
   "source": [
    "## Dataset Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shape_templates and 'train_coco' in locals() and 'val_coco' in locals():\n",
    "    # Analyze class distribution\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATASET ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Training set analysis\n",
    "    print(\"\\nðŸ“Š TRAINING SET:\")\n",
    "    print(f\"  Total images: {len(train_coco['images'])}\")\n",
    "    print(f\"  Total annotations: {len(train_coco['annotations'])}\")\n",
    "    \n",
    "    train_class_counts = Counter([ann['category_id'] for ann in train_coco['annotations']])\n",
    "    print(f\"\\n  Class distribution:\")\n",
    "    for cat in train_coco['categories']:\n",
    "        count = train_class_counts[cat['id']]\n",
    "        print(f\"    - {cat['name']}: {count} instances\")\n",
    "    \n",
    "    # Validation set analysis\n",
    "    print(\"\\nðŸ“Š VALIDATION SET:\")\n",
    "    print(f\"  Total images: {len(val_coco['images'])}\")\n",
    "    print(f\"  Total annotations: {len(val_coco['annotations'])}\")\n",
    "    \n",
    "    val_class_counts = Counter([ann['category_id'] for ann in val_coco['annotations']])\n",
    "    print(f\"\\n  Class distribution:\")\n",
    "    for cat in val_coco['categories']:\n",
    "        count = val_class_counts[cat['id']]\n",
    "        print(f\"    - {cat['name']}: {count} instances\")\n",
    "    \n",
    "    # Average objects per image\n",
    "    avg_train_obj = len(train_coco['annotations']) / len(train_coco['images'])\n",
    "    avg_val_obj = len(val_coco['annotations']) / len(val_coco['images'])\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ STATISTICS:\")\n",
    "    print(f\"  Average objects per training image: {avg_train_obj:.2f}\")\n",
    "    print(f\"  Average objects per validation image: {avg_val_obj:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… Dataset ready for training!\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"Dataset not yet generated. Run the generation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6816516",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After generating the dataset:\n",
    "\n",
    "1. **Review the generated images** in the `output/train/images/` and `output/val/images/` directories\n",
    "2. **Check the annotations** in `output/train/labels.json` and `output/val/labels.json`\n",
    "3. **Train your MediaPipe object detector** using this synthetic dataset\n",
    "4. **Fine-tune parameters** if needed:\n",
    "   - Adjust `num_images` for more training data\n",
    "   - Modify `min_objects` and `max_objects` for different object densities\n",
    "   - Change `background_complexity` for varied backgrounds\n",
    "   - Adjust scale and rotation ranges for different augmentations\n",
    "\n",
    "The dataset is now ready to be used with MediaPipe Object Detector training pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
